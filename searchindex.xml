<?xml version="1.0" encoding="utf-8" standalone="yes"?><search><entry><title>Go中的垃圾回收机制</title><url>https://i.animeii.tech/post/go_xxx_gc/</url><categories><category>后端</category><category>tech</category></categories><tags><tag>go</tag></tags><content type="html"> GoV1.3使用普通标记清除法，整体过程需要启动STW，效率极低。
GoV1.5使用三色标记法，堆空间启动写屏障，栈空间不启动，全部扫描之后，需要重新扫描一次栈(需要STW)，效率普通。
GoV1.8使用三色标记法，混合写屏障机制，栈空间不启动，堆空间启动。整个过程几乎不需要STW，效率较高。
Go V1.3之前的标记-清除算法 步骤：
1. 暂停程序业务逻辑，分类出可达和不可达的对象，然后做标记。
2. 开始标记，程序找出它所有可达的对象，并做上标记。
3. 标记完后，然后开始清除未标记的对象。
4. 停止暂停，让程序继续跑。然后循环重复整个过程，直到process程序生命周期结束。
标记-清除(mark and sweep)的缺点：
1. STW，stop the world；让程序暂停，程序出现卡顿。
2. 标记需要扫描整个heap。
3. 清除数据会产生heap碎片。
Go V1.5的三色标记法 golang中的垃圾回收主要应用三色标记法，GC过程和其他用户goroutine可并发运行，但需要一定时间的STW，所谓三色标记法实际上就是通过三个阶段的标记来确定清除的对象有哪些。
步骤：
1. 每次新创建的对象，默认颜色都是标记为"白色"。
2. 每次GC回收开始，会从根节点开始遍历所有对象，把遍历到的对象从白色集合放入"灰色"集合。
3. 遍历灰色集合，将灰色对象引用的对象从白色集合放入灰色集合，之后将此灰色对象放入黑色集合。
4. 重复第三步，直到灰色中无任何对象。
5. 回收所有的白色标记表的对象。
为了在GC过程中保证数据的安全，在开始三色标记之前就会加上STW，在扫描确定黑白对象之后再结束STW。这样性能依旧很低。
没有STW的三色标记法 在三色标记法中不希望发生的(不启动STW可能存在的情况)：
1. 一个白色对象被黑色对象引用(白色被挂在黑色下)
2. 灰色对象与它之间的可达关系的白色对象遭到破坏(灰色同时丢了该白色)
如果当以上两个条件同时满足时，就会出现对象丢失现象。
防止这种现象最简单的方式就是STW，但STW会极大的浪费资源，降低性能。那么是否可以在保证对象不丢失的情况下提高GC效率，减少STW时间？
屏障机制 强弱三色不变式 强三色不变式：不存在黑色对象引用到白色对象的指针。
弱三色不变式：所有被黑色对象引用的白色对象都处于灰色保护状态。
插入屏障
在A对象引用B对象的时候，B对象被标记为灰色。
满足强三色不变式(白色会强制变成灰色)。
插入写屏障在栈空间的对象操作中不使用，仅仅使用在堆空间对象的操作中。当全部三色标记扫描后，栈上可能依旧存在白色对象被引用的情况，所以要对栈重新进行三色标记扫描，但这次为了对象不丢失，要对本次标记扫描启动STW暂停。直到栈空间的三色标记结束。 删除屏障
被删除的对象，如果自身为灰色或者白色，那么被标记为灰色。
满足弱三色不变式(保护灰色对象到白色对象的路径不会断)。
回收精度低，一个对象即使被删除了最后一个指向它的指针也依旧可以活过这一轮，在下一轮GC中被清除。 Go V1.8混合写屏障(hybrid write barrier)机制 插入写屏障：结束时需要STW来重新扫描栈，标记栈上引用的白色对象的存活。
删除写屏障：回收精度低，GC开始时STW扫描堆栈记录初始快照，这个过程会保护开始时刻的所有存活对象。
混合写屏障，避免了对栈re-scan的过程，极大的减少了STW的时间。
具体流程：
1. GC开始将栈上的对象全部扫描并标记为黑色(之后不再进行第二次重复扫描，无需STW)
4. GC期间，任何在栈上创建的新对象，均为黑色。
3. 被删除的对象标记为灰色。
4. 被添加的对象标记为灰色。
满足变形的弱三色不变式。</content></entry><entry><title>协程调度原理及GMP模型</title><url>https://i.animeii.tech/post/go_xxx_gmp/</url><categories><category>后端</category><category>tech</category></categories><tags><tag>go</tag></tags><content type="html"> go调度器轻量且简单，足以支撑起goroutine的调度工作，并且go具有原生强大的并发能力。go调度本质是把大量的goroutine分配到少量线程去执行，并利用多核并行，实现更强大的并发。
golang调度器的由来 单进程时代不需要调度器
一切的软件都是跑在操作系统上，真正用来计算的是CPU。早期操作系统每个程序就是一个进程，知道一个程序运行完，才能进行下一个进程。一切的程序只能串行发生。
单进程操作系统面临的问题：
单一的执行流程，计算机只能一个任务一个任务处理。 进程阻塞带来的CPU时间浪费。 那么能不能有多个进程来宏观一起执行多个任务呢？ 多进程/线程时代有了调度器的需求
在多进程/多线程的操作系统中，就解决了阻塞的问题，如果一个进程阻塞CPU那么可以立刻切换到其他进程中去执行，而且调度CPU的算法可以保证在运行的进程都可以被分配到CPU的运行时间片。这样从宏观上来看，似乎多个进程在同时被运行。
但新的问题又出现了，进程拥有太多的资源，进程的创建、切换、销毁，都会占用很长的时间，CPU虽然利用起来了，但如果进程过多，CPU有很大一部分都被用来进行进程的调度了。
怎么才能提高CPU的利用率呢？
对于linux系统来说，CPU对进程的态度和线程的态度是一样的。
CPU调度切换的是进程和线程，尽管线程看起来很美好，但实际上多线程开发设计会变得更加复杂，要考虑很多同步竞争等问题，如锁、竞争冲突等。
协程来提高CPU利用率
多进程、多线程已经提高了系统的并发能力，但是在当今互联网高并发场景下，为每个任务都创建一个线程是不现实的，因为会消耗大量的内存(进程虚拟内存会占用4G，而线程也要大约4MB)。
大量的进程/线程出现了新的问题：
高内存占用 调度的高消耗CPU 如何解决这个问题呢？其实线程分为内核态和用户态线程。
一个用户态线程必须要绑定一个内核态线程，但是CPU并不知道用户态线程的存在，它只知道运行的是一个内核态线程(Linux 的PCB进程控制块)。
这样，我们把内核线程叫线程(thread),用户线程叫作协程。
协程与线程的映射关系：
N:1
优点：
协程在用户态线程即完成切换，不会陷入内核态，这种切换非常轻量快速。
缺点:
每个程序用不了硬件的多核加速能力 一旦某个协程阻塞，造成线程阻塞，本进程的其他协程都无法执行了，根本没有并发能力。 1:1
优点：
最容易实现，协程的调度都由CPU完成。
缺点：
协程的创建、删除和切换的代价都由CPU完成。
M:N
克服了上面两种模型的缺点，实现起来复杂。
协程跟线程是有区别的。线程由CPU调度是抢占式的，协程由用户态调度是协作式的，一个协程让出CPU后，才执行下一个协程。
GO的协程gorotine
go为了提供更容易使用的并发方法，goroutine和channel。goroutine来自协程的概念，让一组可复用的函数运行在一组线程上，即使有协程阻塞，该线程的其他协程也可以被runtime调度，转移到其他可运行的线程上。
goroutine非常轻量，只占几KB，并且足够goroutine运行完，这就能在有限的内存空间内支持大量goroutine，支持更多的并发。goroutine栈可伸缩，runtime会自动为goroutine分配。占用内存更小,调度更灵活。
goroutine调度器的GMP模型的设计思想 G: goroutine协程
P: processor 处理器，包含运行goroutine的资源，如果线程想运行goroutine，必须先获取P，P中还包含了可运行的G队列。
M：thread线程
GMP模型
在go中，线程是运行goroutine的实体，调度器的功能是把可运行的goroutine分配到工作线程上。
全局队列：存放等待运行的G。 P的本地队列：存放等待运行的G，数量不超过256个，新建G&rsquo;时，G&rsquo;优先加入到P的本地队列，如果队列满了，则会把本地队列中的一半G移动到全局队列。 P列表：所有P都是在程序启动时创建，并保存在数组中，最多有GOMAXPROCS(可配置)个。 M：线程想要运行任务就得获取P，从P的本地队列获取G，P队列为空时，M也会尝试从全局队列拿一批G放到P的本地队列，或从其他P的本地队列偷一半放在自己P的本地队列。M运行G，G执行之后，M会从P获取下一个G，不断重复下去。 goroutine调度器和os调度器是通过M结合起来的，每个M都代表了1个内核线程，os调度器负责把内核线程分配到CPU的核上执行。
有关P和M的个数问题
M与P的数量没有绝对关系，一个M阻塞，P就会去创建或者切换另一个M，所有，即使P默认数量是1，也有可能会创建很多个M出来。
P的数量：由启动时的环境变量GOMAXPROCS或者由runtime的方法GOMAXPROCS()决定。 M的数量：go默认最大为10000；runtime/debug中的SetMaxThreads函数设置M的最大数量；一个M阻塞了，会创建新的M。 P和M何时会被创建
P何时创建：在确定了P的最大数量n后，运行时系统会根据这个数量创建n个P。 M何时创建：没有足够的M来关联P并运行其中的可运行的G。比如所有的M此时都阻塞了，而P中还有很多就绪任务，就会去寻找空闲的M，如果没有空闲的，就会去创建新的M。 调度器的设计策略
复用线程：避免频发创建、销毁线程，对线程进行复用。
work stealing机制
当本线程无可运行的G时，尝试从其他线程绑定的P偷取G，而不是销毁线程。 hand off机制
当本地线程因为G进行系统调用阻塞时，线程释放绑定的P，把P转移给其他空闲的线程执行。 利用并行：GOMAXPROCS设置P的数量，最多有GOMAXPROCS个线程分布在多个CPU上同时运行。
抢占：在coroutine中要等待一个协程主动让出CPU才执行下一个协程，在Go中，一个goroutine最多占用CPU 10ms，防止其他goroutine被饿死。
全局G队列：当M执行work stealing从其他P偷不到G时，它可以从全局G队列获取G。
go func()调度流程
当M系统调用结束时，这个G会尝试获取一个空闲的P执行，并放入到这个P的本地队列。如果获取不到P，那么这个线程M变成休眠状态，加入到空闲线程中，然后这个G会被放入全局队列中。
调度器的生命周期
M0：是启动程序后编号为0的主线程，这个M对应的实例会在全局变量runtime.m0中，不需要在heap上分配，M0负责执行初始化操作和启动第一个G，在之后M0就和其他的M一样了。
G0：是每次启动一个M都会第一个创建的gorutine,G0是用于负责调度的G，G0不指向任何可执行的函数，每个M都会有一个自己的G0，在调度或系统调用时会使用G0的栈空间，全局变量的G0是M0的G0。</content></entry><entry><title>lru缓存淘汰策略</title><url>https://i.animeii.tech/post/lru/</url><categories><category>后端</category><category>tech</category></categories><tags><tag>go</tag></tags><content type="html"> 缓存淘汰算法：FIFO、LFU和LRU。 FIFO:先进先出，淘汰最早的数据。 LFU：最少使用，淘汰缓存中访问频率最低的。 LRU：最近最少使用。
LRU(Least Recently Used)最近最少使用，相对于仅考虑时间因素的FIFO和仅考虑访问频率的LFU，LRU算法可以认为是相对平衡的一种淘汰算法。LRU认为，如果数据最近被访问过，那么将来被访问的概率也会更高。
LRU算法实现 维护一个队列，如果某条记录被访问了，则移到队尾，那么队首则是最近最少访问的数据，淘汰该条记录即可。
LRU实现的核心数据结构：map、双向链表。 绿色的是map,存储键和值的映射关系。 红色的是双向链表实现的队列。将所有值放到双向链表中，当访问到某个值时，将其移动到队尾的复杂度是O(1)，在队尾新增一条记录以及删除一条记录的复杂度均为O(1)。 package lru import "container/list" type Cache struct{ // 允许使用的最大内存 maxBytes int64 // 当前已使用内存 nbytes int64 ll *list.List cache map[string]*list.Element // 某条记录被移除时的回调函数 OnEvicted func(key string, value Value) } // 双向链表的数据类型 type entry struct{ key string value Value } type Value interface{ // 占用的内存大小 Len() int } // 实例化Cache func New(maxBytes int64,onEvicted func(string,Value)) *Cache { return &amp;Cache{ maxBytes: maxBytes, ll: list.New(), cache: make(map[string]*list.Element), OnEvicted: onEvicted, } } // 查找功能 func (c *Cache) Get(key string) (value Value,ok bool){ // 如果缓存存在 if ele,ok := c.cache[key];ok{ // 节点移到队列前 c.ll.MoveToFront(ele) // 获取缓存 kv := ele.Value.(*entry) // 返回对应的缓存 return kv.value,true } return } // 淘汰缓存 func (c *Cache) RemoveOldest(){ // 取得队尾节点。从链表中移除 ele := c.ll.Back() if ele != nil{ c.ll.Remove(ele) kv := ele.Value.(*entry) // 从cache中移除 delete(c.cache,kv.key) // 归还可用空间 c.nbytes -= int64(len(kv.key)) + int64(kv.value.len()) // 如果回调存在则调用 if c.OnEvicted != nil{ c.OnEvicted(kv.key,kv.value) } } } // 新增、修改 func (c *Cache) Add(key string, value Value){ // 存在时为修改 if ele,ok := c.cache[key];ok{ // 将对应节点移到队首 c.ll.MoveToFront(ele) kv := ele.Value.(*entry) c.nbytes += int64(value.Len()) - int64(kv.value.Len()) kv.value = value }else{ // 新增 在队首添加节点 ele := c.ll.PushFront(&amp;entry{key,value}) c.cache[key] = ele // 更新已用缓存 c.nbytes += int64(len(key)) + int64(value.Len()) } // 当最大缓存容量小于可用容量时移除缓存 for c.maxBytes != 0 &amp;&amp; c.maxBytes &lt; c.nbytes{ c.RemoveOldest() } } // 获取列表长度 func (c *Cache) Len() int { return c.ll.Len() }</content></entry><entry><title>使用ubuntu替代windows</title><url>https://i.animeii.tech/post/why_work_on_linux/</url><categories><category>便捷工具</category></categories><tags><tag>ubuntu</tag></tags><content type="html"> 作为大众使用windows可能是个不错的选择。windows生态非常好，使用简单方便。不过随着linux桌面版的不断发展，也许linux也是一个不错的选择。
为什么选择使用ubuntu作为日常而放弃windows呢？ 首先从我有个人电脑到一年前我都是使用windows，它有丰富的软件生态。用它来娱乐、办公都很不错。但也存在许多问题，虽然病毒少了很多，不过各种软件捆绑广告也让我感到了讨厌。而且我现在玩游戏也并不多，所以windows对我来说非刚需。
选择ubuntu桌面版 现在我全面使用ubuntu，感觉已经回不到windows了。开始我还担心ubuntu软件不够用：比如视频录制、剪辑、下载视频。或者担心软件界面不够友好，选择性太少等等。现在看来完全是多余的担心。对于现在的ubuntu来说只要不是某些特定专业软件，完全够你选择了。而且对于我来说，编程友好的环境、自由的定制、清洁的软件比较重要，使用了一年后我把双系统换成了只用ubuntu。
ubuntu软件推荐 深度终端
相比ubuntu自带的终端颜值高了不少。可设置透明、远程链接、多种界面主题。
网易音乐
edge
kdenlive
视频编辑软件，类似pr
obs studio
录屏很好用
utools
效率管理工具
vscode
xtreme download manager(xdm)
下载软件，可托管浏览器下载
qv2ray
科学上网客户端
motrix
种子下载、磁力链接
ffmpeg
常用来转码视频
you-get
视频下载工具
dbeaver
数据库客户端管理工具</content></entry><entry><title>一致性hash算法</title><url>https://i.animeii.tech/post/consisitenthash/</url><categories><category>后端</category><category>tech</category></categories><tags><tag>go</tag></tags><content type="html"> 一致性hash算法是单节点走向分布式节点的一个重要环节。
什么是一直性哈希算法呢？为什么要使用一致性哈希算法？这和分布式有什么关系？
我该访问谁？
对于分布式缓存来说，当一个节点接收到请求，如果该节点并没有存储缓存值，那么它面临的难题是，从谁那获得数据？ 假设有多个节点，我们用随机选取的方式来决定。那么有很大概率第二次获取相同数据时会访问到其他节点，这将导致我们需要重新从数据源获取数据存储到当前节点。这样一是效率低，二是各个节点存储着相同数据，浪费了大量的存储空间。
那么有什么方法使得相同的key每次都访问到同一节点呢？用hash算法可以做到。我们把key的字符转换成ascii码，再与节点数求余，就可以解决随机算法中，相同key选择不同节点的状况。
节点数量变化了怎么办？
上面的hash算法面临一个问题：当节点节点变化时，所有之前的缓存将全部失效。节点接收到对应请求是，均需要重新去数据源获取数据，将可能发生缓存雪崩。
缓存雪崩：缓存在同一时刻全部失效，造成瞬间DB请求量大、压力骤增，引起雪崩。常因为缓存服务器宕机，或缓存设置了相同的过期时间引起。
那么如何解决这个问题呢？这就需要一致性hash算法了。
算法原理 将key映射到2^32的空间中，将这个数字收尾相连，形成一个环。
将计算节点的哈希值，放在环上。 计算key的哈希值，放在环上，顺时针找到的第一个节点，就是应选取的节点。 一致性哈希算法，在节点改变时，只需要重新定位该节点附近的一下部分数据，而不需要重新定位所有节点。
数据倾斜的问题 当节点数比较少时，会发生key向某个节点倾斜。导致缓存节点负载不均。这时可以采用虚拟节点的方法来处理。
计算虚拟节点的hash值，放置在环上。 计算key的hash值，在环上顺时针寻找到 应选取的虚拟节点，找到对应的真是节点 实现 package consisitenthash import ( "hash/crc32" "sort" "strconv" ) // type func return uint32 type Hash func(data []byte) uint32 type Map struct { hash hash // 虚拟节点个数 replicas int keys []int // 虚拟节点与真实节点映射 // int 虚拟节点的hashkey // string 真实节点的名称 hashMap map[int]string } // 设置虚拟节点数，hash函数 返回Map func New(replicas int, fn Hash) *Map { m := &amp;Map{ replicas: replicas, hash: fn, hashMap: make(map[int]string), } // 没有定义hash时，使用该算法。 if m.hash == nil{ m.hash = crc32.ChecksumIEEE } return m } // 根据节点名称添加虚拟节点 func (m *Map) add(keys ...string){ // 遍历真实节点 for _,key := range keys { // 生成虚拟节点 for i := 0; i &lt; m.replicas; i++{ // 根据编号和真实节点名称 生成虚拟节点哈希 hash := int(m.hash([]byte(strconv.Itoa(i) + key))) // 将虚拟节点加入keys[] m.keys = append(m.keys,hash) // 记录与真实节点的映射 m.hashMap[hash] = key } } // 排序节点环 sort.Ints(m.keys) } func (m *Map) Get(key string) string{ if len(m.keys) == 0{ return "" } hash := int(m.hash([]byte(key))) // 找出匹配到虚拟节点的下标 idx := sort.search(len(m.keys),func(i int) bool{ return m.keys[i] >= hash }) // 因为是环状结构(如果：idx == len(m.keys)，则取m.keys[0])用取余处理。 return m.hashMap[m.keys[idx%len(m.keys)]] }</content></entry><entry><title>go语言高性能编程</title><url>https://i.animeii.tech/post/high_performance/</url><categories><category>后端</category></categories><tags><tag>go</tag></tags><content type="html"> go高性能编程相关。
字符串拼接性能及原理 字符串高效拼接
在go语言中，字符串是不可变的，拼接字符串事实上是创建了一个新的字符串对象。如果存在大量的字符串拼接，对性能产生严重的影响。
1.常见的拼接方式
生成随机字符串
const letterBytes = "abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ" func randomString(n int) string{ b := make([]byte,n) for i := range b { b[i] = letterBytes[rand.Intn(len(letterBytes))] } return string(b) } 使用 + func plusConcat(n int, str string) string { s := "" for i := 0; i &lt; n; i++ { s += str } return s } 使用 fmt.Sprintf func sprintConcat(n int, str string) string { s := "" for i := 0; i &lt; n; i++ { s = fmt.Sprintf("%s%s",s,str) } return s } 使用 string.Builder func builderConcat(n int, str string) string { var builder strings.Builder for i := 0; i &lt; n; i++ { builder.WriteString(str) } return builder.String() } 使用 bytes.Buffer func bufferConcat(n int, str string) string { buf := new(bytes.Buffer) for i := 0; i &lt; n; i++ { buf.WriteString(s) } return buf.String() } 使用 []byte func byteConcat(n int, str string) string { buf := make([]byte,0) for i := 0; i &lt; n; i++ { buf = append(buf,str...) } return string(buf) } 长度可预知，可以分配切片长度，防止内存多次分配。
fuc preByteConcat(n int, str string) string { buf := make([]byte, 0, n*len(str)) for i := 0; i &lt; n; i++ { buf = append(buf, str...) } return string(buf) } 2.benchmark性能比较
func benchmark(b *testing.B, f func(int, string)) { var str = randomString(10) for i := 0; i &lt; b.N; i++ { f(10000, str) } } func BenchmarkPlusConcat(b *testing.B) { benchmark(b,plusConcat)} func BenchmarkSprintfConcat(b *testing.B) { benchmark(b, sprintfConcat)} func BenchmarkBuilderConcat(b *testing.B) { benchmark(b, builderConcat)} func BenchmarkBufferConcat(b *testing.B) { benchmark(b, bufferConcat)} func BenchmarkByteConcat(b *testing.B) { benchmark(b, byteConcat)} func BenchmarkPreByteConcat(b *testing.B) { benchmark(b, preByteConcat)} go test -bench="Concat$" -benchmem . BenchmarkPlusConcat-8 19 56 ms/op 530 MB/op 10026 allocs/op BenchmarkSprintfConcat-8 10 112 ms/op 835 MB/op 37435 allocs/op BenchmarkBuilderConcat-8 8901 0.13 ms/op 0.5 MB/op 23 allocs/op BenchmarkBufferConcat-8 8130 0.14 ms/op 0.4 MB/op 13 allocs/op BenchmarkByteConcat-8 8984 0.12 ms/op 0.6 MB/op 24 allocs/op BenchmarkPreByteConcat-8 17379 0.07 ms/op 0.2 MB/op 2 allocs/op PASS ok example 8.627s 3.建议
综合易用性和性能，推荐使用strings.Builder来拼接字符串。 strings.Builder 预分配内存的方式：
func builderConcat(n int, str string) string { var builder strings.Builder builder.Grow(n * len(str)) for i :=0; i &lt; n; i++ { builder.WriteString(str) } return builder.String() } 与与分配内存[]byte相比，省去了[]byte和字符串string之间的转换，内存分配次数还减少了1次，内存消耗减半。</content></entry><entry><title>间谍过家家</title><url>https://i.animeii.tech/anime/202204/jdgjj/</url><categories><category>视频</category></categories><tags><tag>动漫</tag></tags><content type="html"> #jdgjj-container{ display: grid; grid-template-rows: 300px,200px; place-items: center; } .video-content{ display: grid; align-items: center; } .video-index{ margin-top: 20px; display: grid; grid-template-columns: repeat(4,75px); grid-template-rows: repeat(3,40px); gap: 5px; } .video-index p{ width: 70px; height: 30px; border: 1px dashed gray; border-radius: 3px; /* gap: 5px; */ display: grid; place-items: center; } const base_url = "/_videos/202204/jdgjj/" const num = 12 var video_urls = [] for (var i=1;i' + video_urls[i].name + '
'; } var paa = document.getElementsByClassName('v_url') for (var i=0;i</content></entry><entry><title>面向对象interface</title><url>https://i.animeii.tech/post/go_xxx_interface/</url><categories><category>后端</category></categories><tags><tag>go</tag></tags><content type="html"> interface是go语言的基础特性之一。可以理解为一种类型的规范或者约定。go中的interface是通过约定的形式，隐式的实现。go中的interface让编码更灵活、易扩展。
如何理解go语言中的interface：
1.interface是方法声明的集合
2.任何类型的对象实现了在interface接口中声明的全部方法，则表明该 类型实现了该接口。
3.interface可以作为一种数据类型，实现了该接口的任何对象都可以给对应的接口类型变量赋值。
4.interface可以被任意对象实现，一个类型/对象也可以实现多个interface
5.方法不能重载，如eat(),eat(s string)不能同时存在
package main import "fmt" type Phone interface{ call() } type NokiaPhone struct{ } func (np NokiaPhone) call(){ fmt.Println("I am Nokia,I can call you!") } type ApplePhone struct{ } func (ip ApplePhone) call(){ fmt.Println("I am Apple Phone,I can call you!") } func main(){ var phone Phone phone = new(NokiaPhone) phone.call() phone = new(ApplePhone) phone.call() } 开闭原则定义：
一个软件实体如类、模块和函数应该对扩展开放，对修改关闭。
也就是说在修改需求的时候，应该尽量通过扩展来实现变化，而不是通过修改已有代码来实现。
package main import "fmt" // 抽象的银行业务员 type AbstractBanker interface{ DoBusi() // 抽象的处理业务接口 } // 存款的业务员 type SaveBanker struct{ } func (sv *SaveBanker) DoBusi(){ fmt.Println("进行了存款") } // 转账的业务员 type TransferBanker struct{ } func (tb *TransferBanker) Dobusi(){ fmt.Println("进行了转账") } // 支付的业务员 type PayBanker struct{ } func (pb *PayBanker) DoBusi(){ fmt.Println("进行了支付") } func BankerBusiness(banker AbstractBanker){ // 通过接口来向下调用，（多态现象） banker.DoBusi() } func main(){ // 进行存款 BankerBusiness(&amp;SaveBanker{}) // 进行转账 BankerBusiness(&amp;TransferBanker{}) // 进行支付 BankerBusiness(&amp;PayBanker{}) } 接口的意义：
接口的最大的意义就是实现多态的思想，就是我们可以根据interface类型来设计API接口，那么这种API接口的适应能力不仅能适应当下所实现的全部模块，也适应未来实现的模块来进行调用。
面向抽象层的依赖倒转:
如果我们在设计一个系统的时候，将模块分为3个层次，抽象层、实现层、业务逻辑层。设计抽象层，根据抽象层实现。我们在指定业务逻辑也是一样，抽象层暴露出来的接口就是我们业务层可以使用的方法，然后可以通过多态，接口指针指向哪个实现模块，调用的就是具体的实现方法，这样我们业务逻辑层也是依赖抽象层编程。这种设计原则就是依赖倒转原则
package main import "fmt" // --- 抽象层 --- type Car interface{ Run() } type Driver interface{ Drive(car Car) } // --- 实现层 --- type Benz struct{ } func (bz *Benz) Run(){ fmt.Println("Benz is running...") } type Bmw struct{ } func (bmw *Bmw) Run(){ fmt.Println("Bmw is running...") } type Zhang struct{ } func (z *Zhang) Drive(car Car){ fmt.Println("zhang drive car") car.Run() } func Li struct{ } func (l *Li) Drive(car Car){ fmt.Println("li drive car") car.Run() } // --- 业务逻辑 --- func main(){ var bmw Car bmw = &amp;Bmw{} var zhang Driver zhang = &amp;Zhang{} zhang.Drive(bmw) var benz Car benz = &amp;Benz{} var li Driver li = &amp;Li{} li.Drive(benz) } package main import "fmt" // 抽象层 type Card interface{ Display() } type Memory interface{ Storage() } type CPU interface{ Calculate() } type Computer struct{ cpu CPU mem Memory card Card } func NewComputer(cpu CPU,mem Memory,card Card) *Computer{ return &amp;Computer{ cpu:cpu, mem:mem, card:card, } } func (c *Computer) DoWork(){ c.cpu.Calculate() c.mem.Storage() c.card.Display() } // 实现层 type IntelCPU struct{ CPU } func (ic *IntelCPU) Calculate(){ fmt.Println("Intel CPU 开始计算了...") } type IntelMemory struct{ Memory } func (im *IntelMemory) Storage(){ fmt.Println("Intel Memory 开始存储了...") } type IntelCard struct{ Card } func (ic *IntelCard) Display(){ fmt.Println("Intel Card 开始显示了...") } type KingstonMemory struct{ Memory } func (km *KingstonMemory) Storage(){ fmt.Println("Kingston memory storage...") } type NvidiaCard struct{ Card } func (nc *NvidiaCard) Dispaly(){ fmt.Println("Nvidia card display...") } // 业务层 func main(){ com1 := NewComputer(&amp;IntelCPU{},&amp;IntelMemory{},&amp;IntelCard{}) com1.DoWork() com2 := NewComputer(&amp;IntelCPU{},&amp;KingstonMemory{},&amp;NvidiaCard{}) com2.DoWork() }</content></entry><entry><title>切片</title><url>https://i.animeii.tech/post/go_xxx_slice/</url><categories><category>后端</category></categories><tags><tag>go</tag></tags><content type="html"> 切片相关
切片的初始化与追加
package main import ( "fmt" ) func main(){ s := make([]int,10) s = append(s,1,2,3) fmt.Println(s) } // make初始化为0 // [0 0 0 0 0 0 0 0 0 0 1 2 3] slice拼接问题
package main import "fmt" func main(){ s1 := []int{1,2,3} s2 := []int{4,5} // s1 = append(s1,s2) // 编译失败 s1 = append(s1,s2...) fmt.Println(s1) } slice中new的使用
package main import "fmt" func main(){ list := new([]int) list = append(list,1) fmt.Println(list) } // 编译失败 // first argument to append must be slice; have *[]int 切片指针的解引用
1.使用list := make([]int,0) list类型为切片
2.使用*list = append(*list,1) list类型为指针
new和make的区别：
二者都是内存的分配（堆上），但make只用于slice、map及channel的初始化；而new用于类型的内存分配，并且内置为零。
make返回的是这几个引用类型本身；而new返回的是指向类型的指针。</content></entry><entry><title>数据定义</title><url>https://i.animeii.tech/post/go_xxx_data_define/</url><categories><category>后端</category></categories><tags><tag>go</tag></tags><content type="html"> 函数返回值、结构体比较、string与nil类型、常量。
函数返回值的问题
package main func myFunc(x,y int) (sum int,error){ return x+y,nil } func main(){ num,err := myFunc(1,2) fmt.Println("num = ",num) } // 编译报错 // syntax error: mixed named and unnamed function parameters 在函数有多个返回值时，只要有一个返回值有指定命名，其他的也必须有命名。
结构体比较问题
1.只有相同类型的结构体才可以比较，结构体是否相同不但与属性类型个数有关，还与属性顺序有关。
2.结构体是有相同的，但是结构体属性中有不可以比较的类型，如map,slice,则结构体不能用==比较。
可以使用reflect.DeepEqual进行比较
if reflect.DeepEqual(sm1,sm2){ fmt.Println("sm1 == sm2") }else{ fmt.Println("sm1 != sm2") } string与nil类型
不能将nil作为string返回值。
nil可以用作interface,function,pointer,map,slice,channel的空值。但是如果不特别制定的话，go语言不能识别类型，所有会报错。通常编译的时候不会报错，但是运行的时候会报：cannot use nil as type string in return argument
常量
package main const cl = 100 var bl = 123 func main(){ println(&amp;bl,bl) println(&amp;cl,cl) } // cannot take the address of cl 常量不同于变量的运行期分配内存，常量通常会被编译器在预处理阶段直接展开，作为指令数据使用。
内存四区概念
1.数据类型本质
固定内存大小的别名。
2.数据类型的作用
编译器预算对象（变量）分配的内存空间大小。
3.内存四区
流程说明
1.操作系统把物理硬盘代码load到内存
2.操作系统把c代码分成四个区
3.操作系统找到main函数入口执行
栈区（Stack）:
空间较小，要求数据读写性能高，数据存放时间较短暂。由编译器自动分配和释放，存放函数的参数值、函数的调用流程方法地址、局部变量等（局部变量如果产生逃逸现象，可能会挂在在堆上）
堆区（heap):
空间充裕，数据存放时间较久。golang中会根据变量的逃逸现象来选择是否分配到栈上或堆上，由GC清除机制自动回收。
全局区-静态全局变量区：
全局变量的开辟是在程序在main之前就已经放在内存中。而且对外完全可见。即作用域在全部代码中，任何同包代码均可随时使用，在变量会搞混淆，而且在局部函数中如果同名称变量使用:=赋值会出现编译错误。
全局变量最终在进程退出时，由操作系统回收。
全局区-常量区：
常量区也是属于全局区，常量为存放数值字面值单位，即可以修改。或者说有的常量是直接挂钩字面值。const cl = 10。所以在golang中，常量是无法取出地址的，因为字面量符号并没有地址而言。</content></entry><entry><title>go中channel的使用</title><url>https://i.animeii.tech/post/go_xxx_channel/</url><categories><category>后端</category></categories><tags><tag>go</tag></tags><content type="html"> go中channel的使用规则。
channel的特性：
1.给一个nil channel发送数据，造成永远阻塞。
2.给一个nil channel接收数据，造成永远阻塞。
3.给一个已经关闭的channel发送数据，引起panic。
4.从一个已经关闭的channel接收数据，如果缓冲区中为空，则返回一个零值。
5.无缓冲的channel是同步的，而有缓冲的channel是非同步的。
package main import( "fmt" "time" ) func main(){ ch := make(chan int,1000) go func(){ for i := 0; i &lt; 10;i++{ ch &lt;- i } }() go func(){ for { a,ok := &lt;-ch if !ok { fmt.Println("close") return } fmt.Println("a: ",a) } }() close(ch) // close fmt.Println("ok") time.Sleep(time.Second * 100) } // painc: send on closed channel</content></entry><entry><title>go中defer的使用</title><url>https://i.animeii.tech/post/go_xxx_defer/</url><categories><category>后端</category></categories><tags><tag>go</tag></tags><content type="html"> go中多个defer执行为栈。遵循先进后出原则。
defer的执行顺序
多个defer执行顺序为：先进后出的关系。一个函数中，写在前面的defer会与写在后面的defer调用的晚。
package main import "fmt" func main(){ defer func1() defer func2() defer func3() } func func1(){ fmt.Println("A") } func func2(){ fmt.Println("B") } func func3(){ fmt.Println("C") } // output: // C // B // A defer与return谁先谁后
return先执行，return后执行。
package main import "fmt" func deferFunc() int { fmt.Println("defer func called") return 0 } func returnFunc() int { fmt.Println("return func called") return 0 } func returnAndDefer() int { defer deferFunc() return returnFunc() } func main() { returnAndDefer() } // output: // return func called // defer func called 函数返回值的初始化
func DeferFunc(i int) (t int) {}其中返回值t int,这个t会在函数其实从被初始化为对应类型的零值并且作用域为整个函数。
package main import "fmt" func DeferFunc(i int) (t int){ fmt.Println("t = ",t) return 2 } func main(){ DeferFunc(10) } // output: // t = 0 函数命名返回值遇到defer的情况
执行完return后再执行defer里的语句，依然可以修改本应该返回的结果。
package main import "fmt" func returnButDefer() (t int) { // 0 10 defer func() { t = t * 10 // t = 10 ^ }() return 1 // t = 1 } func main(){ fmt.Println(returnButDefer()) // 10 } // 初始化t->入栈defer->return->出栈执行defer函数->t = 10->函数返回10 defer遇到panic
能够触发defer的是遇到return、遇到panic、函数体到末尾。
1.defer遇到panic，但并不捕获异常的情况。
package main import( "fmt" ) func main(){ defer_call() fmt.Println("main 正常结束") } func defer_call(){ defer func() { fmt.Println("defer: panic 之前1") }() defer func() { fmt.Println("defer: panic 之前2") }() panic("异常内容") // 触发defer出栈 defer func(){ fmt.Println("defer: panic 之后，永远执行不到") } } // output: // defer: panic 之前2 // defer: panic 之前1 // panic: 异常内容 // ... 异常堆栈信息 2.defer遇到panic，并捕获异常
package main import ( "fmt" ) func main(){ defer_call() fmt.Println("main 正常结束") } func defer_call(){ defer func(){ fmt.Println("defer: panic 之前1，捕获异常") if err := recover(); err != nil{ fmt.Println(err) } }() defer func(){ fmt.Println("defer: panic 之前2，不捕获")}() panic("异常内容") defer func(){ fmt.Println("defer: painc 之后，永远执行不到")}() } // output: // defer: panic 之前2，不捕获 // defer: panic 之前1，捕获异常 // 异常内容 // main 正常结束 defer的最大的功能是panic后依然有效
所以defer可以保证你的一些资源一定会被关闭，从而避免一些异常出现的问题。
defer中包含panic
package main import( "fmt" ) func main(){ if err := recover(); err != nil{ fmt.Println(err) }else{ fmt.Println("fatal") } }() defer func(){ panic("defer panic") }() panic("panic") // output: // defer panic defer下的函数参数包含子函数
package main import "fmt" func function(index int, value int) int{ fmt.Println(index) return index } func main(){ defer function(1,function(3,0)) defer function(2,function(4,0)) } // output: // 3 // 4 // 2 // 1 执行顺序：
1.defer压栈function1，压栈函数地址、形参1、形参2（调用function3）->打印3
2.defer压栈function2，压栈函数地址、形参1、形参2（调用function4）->打印4
3.defer出栈function2，调用function2->打印2
4.defer出栈function1，调用function1->打印1
package main import "fmt" func DeferFunc1(i int) (t int){ t = i defer func(){ t += 3 }() return t } func DeferFunc2(i int) int { t := i defer func(){ t += 3 }() return t // 把t赋值给返回值 } func DeferFunc3(i int) (t int){ defer func(){ t += i }() return 2 } func DeferFunc4() (t int) { defer func(i int) { fmt.Println(i) // 0 fmt.Println(t) // 2 }(t)// t = 0 入参 t = 1 return 2 // t = 2 } func main(){ fmt.Println(DeferFunc1(1)) fmt.Println(DeferFunc2(1)) fmt.Println(DeferFunc3(1)) DeferFunc4() } // output: // 4 // 1 // 3 // 0 // 2</content></entry><entry><title>视频首页</title><url>https://i.animeii.tech/anime/av/</url><categories><category>视频</category></categories><tags/><content type="html"> 鬼灭之刃第二季
间谍过家家
.an-container{ display: grid; grid-template-rows: 350px; /* */ /* align-items: center; */ padding: 10px; /* border: 2px dashed gray; */ } .an-text{ display: grid; grid-template-columns: repeat(2,180px); grid-template-rows: repeat(3,40px); gap: 5px; } .an-text p{ width: 160px; height: 30px; border: 1px dashed gray; border-radius: 3px; display: grid; place-self:center; place-items: center; }</content></entry><entry><title>鬼灭之刃第二季</title><url>https://i.animeii.tech/anime/gmzr2/</url><categories><category>视频</category></categories><tags><tag>动漫</tag></tags><content type="html"> #gmzr2-container{ display: grid; grid-template-rows: 300px,200px; place-items: center; } .video-content{ display: grid; align-items: center; } .video-index{ margin-top: 20px; display: grid; grid-template-columns: repeat(4,75px); grid-template-rows: repeat(3,40px); gap: 5px; } .video-index p{ width: 70px; height: 30px; border: 1px dashed gray; border-radius: 3px; /* gap: 5px; */ display: grid; place-items: center; } const base_url = "https://ewr1.vultrobjects.com/animeii/video/gmzr2/" const num = 11 var video_urls = [] for (var i=1;i' + video_urls[i].name + '
'; } var paa = document.getElementsByClassName('v_url') for (var i=0;i</content></entry><entry><title>通过s3cmd管理对象存储</title><url>https://i.animeii.tech/post/manage_object_storage_by_s3cmd/</url><categories><category>websit</category><category>tech</category></categories><tags><tag>bolg</tag></tags><content type="html"> 我需要有存储、管理我的图片及媒体文件。服务器硬盘资源有限，如何扩展呢？加硬盘？最终我选择使用对象存储来解决这一问题。本文为网站s3cmd命令行工具管理对象存储的实践。
因为我是使用vultr的产品。所有我在该云平台上创建一个对象存储实例。具体为$5-1T-250G（价格-流量-存储空间）。对于一个小网站来说足够了。有特殊需求再来扩展。于是我就寻找方便管理存储的工具，S3cmd好像挺不错的。
安装s3cmd
# 使用python3包管理工具 pip3 install s3cmd 配置s3cmd
配置使其与自己创建的对象存储关联。
# 根据提示配置 s3cmd --configure # 需要填写的是： # access key/secret key/endpoint(ewr1.vultrobjects.com) # dns-style(%(bucket).ewr1.vultrobjects.com) # 以上信息都可以在对象存储实例详情中找到 使用s3cmd
# 创建bucket s3cmd mb s3://mybucket # 删除bucket s3cmd rb s3://mybucket # 列出bucket s3cmd ls # 列出bucket中的对象 s3cmd ls s3://mybucket # 上传私有文件 s3cmd put photo.jpg s3://mybucket/photo.jpg # 上传公共文件 --recursive s3cmd put -P photo.jpg s3://mybucket/photo.jpg # 下载文件 s3cmd get s3://mybucket/photo.jpg # 删除文件 s3cmd rm s3://mybucket/photo.jpg # 更新文件为公共访问 s3cmd setacl s3://mybucket/photo.jpg --acl-public # 更新文件为私有访问 s3cmd setacl s3://mybucket/photo.jpg --acl-private # 为bucket启用公共目录列表 s3cmd setacl s3://mybucket/ --acl-public # 为bucket启用私有目录列表 s3cmd setacl s3://mybucket/ --acl-private 上传速度
上传网站图片到对象存储，将图片链接替换成生成的链接。
遇到的问题
在使用s3cmd命令时大多数出现连接被拒绝。这让我很困扰，我知道是网络原因，但无论我怎么更换各种不同的网络源，始终还是这样。搜索引擎搜索也没有结果。最终解决方法是在配置s3cmd --configure设置http代理。</content></entry><entry><title>如何自动更新网站内容</title><url>https://i.animeii.tech/post/sync_push_by_webhook/</url><categories><category>hugo</category><category>tech</category></categories><tags><tag>bolg</tag></tags><content type="html"> 有这样一个需求：在本地编写、管理网站文章，怎样自动的部署到远程服务器上？通过webhook当我编写完文档后，push到github时，会自动部署到远程服务器上。这样既能满足本地快捷的编写文档，又不受限于本地开关机状态。
本文为将博客自动部署到远程vps的实践。
在github创建代码仓库
在github上创建一个公共仓库。将博客的public下的文件提交到该仓库
vps上的准备
1.生成ssh-key,添加到github
# 生成公钥 ssh-keygen -C "animeic@163.com" # 查看并添加到GitHub cat .ssh/id_rsa.pub # 验证 ssh -vT git@github.com # 在github添加 2.安装webhook服务。
apt-get install webhook # 启动服务 webhook -hooks /etc/webhook.yaml # [/etc/webhook.yaml 配置] - id: redeploy-webhook execute-command: "/var/scripts/redeploy.sh" # 执行的脚本 command-working-directory: "/root/i.animeii.tech/static/i.animeii.tech" #需要拉取文件的目录 # 推荐设置system管理，参考如《何创建一个博客网站》中frps的配置方式 # [/var/scripts/redeply.sh 配置] #!/bin/bash git pull git@github.com:animeic/i.animeii.tech.git # 需要注意/root/i.animeii.tech/static/i.animeii.tech 需要git初始化。git init 上面创建的仓库设置webhook
vps上配置nginx使能被http访问到
因为frp与nginx端口冲突，我使用go的gin框架做了个静态服务。
https://github.com/animeic/animeii_main/tree/main/i.animeii.tech
├── bootstrap │ └── initGin.go ├── go.mod ├── go.sum ├── main.go ├── middleware │ └── Cors.go ├── router │ └── initRouter.go ├── static └── i.animeii.tech # 网页文件的根目录 # 编译 go build -o web # 后台启动 nohup ./web &amp; 总结：
1.本地编写文档生成静态文件。git push到代码仓库。
2.github触发push事件。以post方式请求配置的webhook服务接口。
3.webhook接口执行服务器上配置的脚本，pull静态文件到具体目录。
4.配置nginx指向这个目录，使能被web访问。
于是做到了本地编写、管理网站文档。
遇到的问题：
git提交时出现kex_exchange_identification: read: Connection reset by peer
排查方法：ssh -vT git@github.com发现连接github服务器失败。网络原因。</content></entry><entry><title>常用软件安装流程</title><url>https://i.animeii.tech/post/common_use_software_install/</url><categories><category>hugo</category><category>tech</category></categories><tags><tag>bolg</tag></tags><content type="html"> 常用软件安装流程。
go安装 wget https://golang.google.cn/dl/go1.17.2.linux-amd64.tar.gz tar -zxvf go1.17.2.linux-amd64.tar.gz cp -r go /usr/local/ vim /etc/profile # 末尾添加 export GOROOT=/usr/local/go export PATH=$PATH:$GOROOT/bin source profile # 开启模块 go env -w GO111MODULE=on # 设置代理 go env -w GOPROXY=https://goproxy.cn,direct Redis安装 wget https://download.redis.io/releases/redis-6.2.6.tar.gz tar -zxvf redis-6.2.6.tar.gz make make install cp utils/redis_init_script /etc/init.d/redisd ### 根据脚本中的内容创建目录 mkdir /etc/redis chmod +x /etc/init.d/redisd cd /etc/init.d/ update-rc.d redisd defaults ## service启动 service redisd start service redisd restart service redisd stop ### 截取的脚本中的部分内容 REDISPORT=6379 EXEC=/usr/local/bin/redis-server CLIEXEC=/usr/local/bin/redis-cli PIDFILE=/var/run/redis_${REDISPORT}.pid CONF="/etc/redis/${REDISPORT}.conf"</content></entry><entry><title>Hugo建站相关</title><url>https://i.animeii.tech/post/use_hugo_any/</url><categories><category>hugo</category><category>tech</category></categories><tags><tag>bolg</tag></tags><content type="html"> 扩展网站功能，如何添加音乐、评论系统。在使用博客中，不断扩展其内容。自定义一些功能。
添加评论系统 因为国内网络原因，这里选用utterances作为网站的评论系统。本质上是使用github的issue功能。
step1：新建public github仓库
step2：安装utterances
在github导航栏，Marketplace。搜索并安装utterances，选择上面已创建的git仓库。
step3：在hugo配置文件加入配置
## 配置 utteranc评论,教程参考 https://utteranc.es/ [params.utteranc] enable = true repo = "animeic/bolgtalks" # user/repo issueTerm = "pathname" theme = "github-light" step4：添加代码到hugo主题具体模板内，展示评论
{{ if .Site.Params.utteranc.enable }} &lt;script src="https://utteranc.es/client.js" repo="{{ .Site.Params.utteranc.repo }}" issue-term="{{ .Site.Params.utteranc.issueTerm }}" theme="{{ .Site.Params.utteranc.theme }}" crossorigin="anonymous" async> &lt;/script> {{ end }} 具体效果：
添加网易音乐 1.在站点引入
step1：在网易云页面找到iframe外链代码
step2：配置文件中配置音乐链接地址
step3：在站点模板中加入具体代码
2.在具体文章页面引入
在文章markdown中加入下面的代码
&lt;!-- cloud music --> &lt;iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width=100% height=52 src="//music.163.com/outchain/player?type=2&amp;id=1897084229&amp;auto=1&amp;height=32">&lt;/iframe></content></entry><entry><title>为什么要做这个博客网站</title><url>https://i.animeii.tech/about/</url><categories><category>website</category><category>life</category></categories><tags><tag>bolg</tag></tags><content type="html"> 其实一直都有创建一个个人站点的的想法。主要用于记录、总结、规划。对于已经经历的事物，总是不得要领，重复重复的低效中度过。虽然重复是人类的本质。
我需要一个工具来使自己有效率。对已经历、已思辨的东西，在遇到的时候能进一步的发现不同。而不单单是低效率的重复。阅读使人充实，谈论使人机敏，写作使人精确。搭建一个个人网站，用于总结以往的经验，思考一些现象和制定目标，通过互联网分享。如果能坚持下去，可以给自己正反馈，相信自己也会变得更有条理。
本站使用vps+frp实现。外网访问本地服务。例如：访问https://i.animeii.tech实际访问的是本地nginx指向的本机静态文件。
使用的产品和技术：
vps：独立ip用于实现外网访问。
frp：内网穿透，用于通过vps转发请求到本地服务。
域名：实现域名访问。
ssl：实现https
cloudflare：用于dns、cdn
hugo：用于生成静态页面。</content></entry><entry><title>使用hugo生成文档页面的流程</title><url>https://i.animeii.tech/post/create_web_page/</url><categories><category>hugo</category><category>tech</category></categories><tags><tag>bolg</tag></tags><content type="html"> hugo生成静态页面的流程。方便流畅的记录内容。
1.设置文章头模板文件。网站根目录下archetypes/default.md
+++ author = "{{ .Site.Params.AuthorName }}" title = "{{ replace .Name "-" " " | title }}" date = {{ .Date }} description = "{{ replace .Name "-" " " | title }}" tags = [ "bolg", ] categories = [ "hugo", "tech", ] +++ 这里是文章概述。。。 &lt;!--more--> 2.新建文档文件
# 在hugo站点根目录执行 hugo new post/doc_name.md 3.书写文档主体
使用markdown编辑器编写文档。修改模板头信息，确定好文章的分类、标签、概述。。。
4.生成html页面
# 推荐使用下面命令生成静态页面。防止页面、图片不生效 hugo -e -production --forceSyncStatic --gc 5.ctrl+F5刷新浏览器。即可在网页上看到文档内容。</content></entry><entry><title>如何创建一个博客网站</title><url>https://i.animeii.tech/post/how_build_bolg_website/</url><categories><category>website</category><category>tech</category></categories><tags><tag>bolg</tag></tags><content type="html"> 本文是本人创建博客站点的整个流程。通过https://i.animeii.tech即可访问到我的站点。其中使用到内网穿透、cloudflare的cdn加速、网站的https访问以及hugo的使用。
如何创建一个博客网站？ 环境：linux桌面版
资源准备
购买vps。 购买域名。我买的域名后缀是.tech，首年9元。 域名和vps相关准备
注册cloudflare，在注册域名平台（如腾讯云）更改为cloudflare域名服务器地址。 在cloudflare上解析域名，建立域名与ip的映射。 在域名注册平台申请免费的ssl证书。 下载nginx部署证书，根据站点命名。如i.animeii.tech.key i.animeic.tech.pem 安装、配置frp
github上搜索frp。下载对应安装包。 # 分别在本地机器和vps上下载 wget https://github.com/fatedier/frp/releases/download/v0.40.0/frp_0.40.0_linux_386.tar.gz 解压安装包，配置frpc和frps # 分别解压 tar -zxvf frp_0.40.0_linux_386.tar.gz # [vps]配置frps mkdir /etc/frp cp frps.ini /etc/frp/frps.ini cp frps /usr/bin/ cp -r sysytem/frps.service /etc/systemd/system/ # 更改frps.service脚本 vim /etc/systemd/system/frps.service [Service] ... User=root # 防止service方式启动主进程死掉 ... # 设置system启动 systemctl enable frps.service # 管理 systemctl start/stop/status frps.service # 或者 service frps start/stop/status # 配置frps.ini文件 # vim /etc/frp/frps.ini [common] bind_port = 7000 vhost_http_port = 80 vhost_https_port = 443 # 启动frps service frps start # [local] 本机配置frpc，注意frpc.ini是配置重点 # frpc的system管理和frps一致。 # 重点配置 root@animeic-pc:/etc/frp# tree ├── frpc.ini └── ssl ├── i.animeii.tech.key ├── i.animeii.tech.pem └── i.animeii.tech.zip # -----配置frpc.ini----- [common] server_addr = 207.246.100.83 # vps ip地址 server_port = 7000 # 对应vps bind_port # 配置https [https-i.animeii.tech] type = https custom_domains = i.animeii.tech plugin = https2http plugin_local_addr = 127.0.0.1:8081 # 证书配置 plugin_crt_path = /etc/frp/ssl/i.animeii.tech.pem plugin_key_path = /etc/frp/ssl/i.animeii.tech.key plugin_host_header_rewrite = 127.0.0.1 plugin_header_X-From-Where = frp # 配合nginx使用 # /etc/nginx/conf.d/i.animeii.tech.conf server { listen 8081; server_name 127.0.0.1; root /home/animeic/animeii/i.animeii.tech/public; # hugo生成的静态文件路径 location / { index index.html; try_files $uri $uri/ /index.html; } } # 启动frpc和nginx service frpc start nginx -s reload cloudflare cdn加速和开启ssl
在站点的dns项目下，开启代理小黄云
在ssl/tls 开启严格加密模式
在边缘证书下开启http定向的https
安装hugo
# 1.克隆安装 git clone https://github.com/gohugoio/hugo.git CGO_ENABLED=1 go install --tags extended # sass支持 # 2.编译后的执行文件复制到/usr/bin cd $GOPATH/bin sudo cp hugo /usr/bin/ 创建站点
hugo new site /animeii.tech/i.animeii.tech # 运行本地服务 hugo server 生成静态文件。nginx配置指向静态文件路径。
# 创建文档 hugo new post/how_build_website.md # 生成静态html hugo # 会在 i.animeii.tech生成public文件，nginx指向这个路径即可 整个建站流程大致是这样。如果已完成上面的过程，即可通过具体域名，外网访问到本地服务。
强调一下，使用frp内网穿透。完全是为了自己的需求：节省服务器资源、方便编写文档、数据的完全掌控、便于以后扩展其他服务。你完全可以不使用项技术，直接部署在云服务器上也是没问题的。
其中hugo主题的安装、配置。需要自己研究。之后再来开展相关内容。</content></entry></search>